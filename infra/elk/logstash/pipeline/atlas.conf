input {
  beats {
    port => 5044
  }
}

# Option A (P0): Filebeat already decodes NDJSON (LogstashEncoder) and ships
# structured fields at the root event level (target: "").
# Therefore Logstash MUST NOT try to JSON-parse the [message] field again.
filter {
  # Parse the timestamp if present (Spring LogstashEncoder uses ISO8601)
  if [@timestamp] {
    date {
      match => ["@timestamp", "ISO8601"]
    }
  }

  # Normalize a few common keys for easier querying in Kibana.
  # Keep the original keys as well when possible (safer for dashboards).
  mutate {
    rename => {
      "logger_name" => "logger"
      "thread_name" => "thread"
      "message" => "msg"
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "atlas-logs-%{+YYYY.MM.dd}"
  }

  # Useful for debugging the pipeline; keep enabled for local docker.
  stdout { codec => rubydebug { metadata => false } }
}
