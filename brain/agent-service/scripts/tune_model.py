import os
import sys
import time
import json
import argparse
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# ----- Configuration Path -----
env_path = Path(__file__).resolve().parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY or API_KEY == "change-me":
    print("‚ùå Erreur : OPENAI_API_KEY manquante ou invalide dans le fichier .env")
    sys.exit(1)

client = OpenAI(api_key=API_KEY)

# ----- Versioning Paths -----
DATASETS_DIR = Path(__file__).resolve().parent.parent.parent / "datasets"
HISTORY_FILE = Path(__file__).resolve().parent / "tune_history.json"

# Mod√®le original d'OpenAI utilis√© tout au d√©but
FOUNDATION_MODEL = "gpt-4o-mini-2024-07-18"

def load_history():
    if not HISTORY_FILE.exists():
        return {"versions": []}
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def save_history(history):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, indent=4, ensure_ascii=False)

def get_base_model(history):
    """
    Retourne le dernier mod√®le fine-tun√© g√©n√©r√©. 
    S'il n'y en a aucun, retourne le mod√®le de fondation OpenAI.
    """
    if not history["versions"]:
        return FOUNDATION_MODEL
    
    # On prend l'ID du dernier entra√Ænement r√©ussi
    latest_version = history["versions"][-1]
    last_model_id = latest_version.get("model_id")
    
    return last_model_id if last_model_id else FOUNDATION_MODEL

def upload_and_train(dataset_path: Path, base_model: str, version_tag: str):
    if not dataset_path.exists():
        print(f"‚ùå Erreur : Le dataset delta introuvable √† {dataset_path}")
        sys.exit(1)
        
    print(f"üîÑ Delta Training : {dataset_path.name}")
    print(f"üèó Mod√®le de base : {base_model}")
        
    print(f"\n‚è≥ 1. Upload du dataset (Delta) vers OpenAI...")
    with open(dataset_path, "rb") as f:
        file_response = client.files.create(
            file=f,
            purpose="fine-tune"
        )
    file_id = file_response.id
    print(f"‚úÖ Upload r√©ussi ! File ID: {file_id}")
    
    # Wait briefly for file processing
    time.sleep(5)
    
    print(f"\n‚è≥ 2. Lancement du job de Fine-Tuning sur {base_model}")
    try:
        job = client.fine_tuning.jobs.create(
            training_file=file_id,
            model=base_model,
            suffix=f"atlas-{version_tag}"
        )
        job_id = job.id
        print(f"‚úÖ Job de Fine-Tuning d√©marr√© ! Job ID: {job_id}")
        print(f"Vous pouvez monitorer l'avancement sur : https://platform.openai.com/finetune")
        
        print("\n‚è≥ 3. Monitoring du job (Appuyez sur Ctrl+C pour quitter mais laisser tourner en t√¢che de fond)")
        while True:
            status_response = client.fine_tuning.jobs.retrieve(job_id)
            status = status_response.status
            
            if status == "succeeded":
                fine_tuned_model = status_response.fine_tuned_model
                print(f"\nüéâ SUCC√àS ! Mod√®le entrain√© avec succ√®s.")
                print(f"ü§ñ NOVEAU MODEL ID : {fine_tuned_model}")
                
                # Mise √† jour de l'historique
                history = load_history()
                history["versions"].append({
                    "version_tag": version_tag,
                    "dataset_file": dataset_path.name,
                    "base_model_used": base_model,
                    "model_id": fine_tuned_model,
                    "job_id": job_id,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                })
                save_history(history)
                print(f"‚úÖ Historique mis √† jour dans {HISTORY_FILE.name}")
                print(f"üëâ Mettez √† jour votre variable OPENAI_MODEL dans .env avec '{fine_tuned_model}' !")
                break
            elif status in ["failed", "cancelled"]:
                print(f"\n‚ùå ERREUR : Le job a √©chou√© ou a √©t√© annul√©. Statut: {status}")
                break
            
            print(f"Statut actuel : {status}... (v√©rification dans 30s)")
            time.sleep(30)
            
    except Exception as e:
        print(f"\n‚ùå Erreur inattendue lors du fine-tuning : {e}")

def main():
    parser = argparse.ArgumentParser(description="Atlas Delta Fine-Tuner (Continuous Training)")
    parser.add_argument("dataset", type=str, help="Nom du fichier JSONL (ex: v2_create_contract.jsonl)")
    parser.add_argument("--force-base", type=str, default=None, help="Forcer un mod√®le de base sp√©cifique (ID) au lieu d'utiliser le dernier mod√®le g√©n√©r√©")
    
    args = parser.parse_args()
    
    dataset_file = Path(args.dataset)
    version_tag = dataset_file.stem.split('_')[0][:10] # e.g., 'v2' from 'v2_create_contract.jsonl'
    
    # 1. On cherche le dataset dans le dossier "datasets" ou dans le r√©pertoire courant
    dataset_path = DATASETS_DIR / dataset_file.name
    if not dataset_path.exists():
        dataset_path = dataset_file # Fallback chemin absolu/relatif fourni
    
    # 2. On d√©termine le mod√®le de base (Foundation ou le pr√©c√©dent)
    history = load_history()
    base_model = args.force_base if args.force_base else get_base_model(history)
    
    upload_and_train(dataset_path, base_model, version_tag)

if __name__ == "__main__":
    main()
